"""
Inter-Subject Correlation (ISC) Analysis for Coherograms
=========================================================

This script computes ISC across subjects for each drug condition to create
a "similarity coherogram" showing where and when subjects show consistent
coherence patterns after drug administration.

INTEGRATION WITH EXISTING CODE:
-------------------------------
This script uses the load_experiment() function from your existing
coherence_analysis_ephys_calcium.py file. It does NOT require explicit
file paths because your data loading is handled by:
- EphysAPI (loads ephys data from line_num)
- MiniscopeDataManager (loads miniscope data from line_num)
- Only explicit path needed: meanFluorescence files in BASE_DATA_PATH

CONFIGURATION:
--------------
1. Set BASE_DATA_PATH to your meanFluorescence directory
2. Set CHANNEL_NAME to match your channel ('CBvsPCEEG', 'PFCLFPvsCBEEG', etc.)
3. Ensure your src2 modules are importable

Author: Generated for neuroscience publication
Date: 2025
"""

import numpy as np
import matplotlib.pyplot as plt
import xarray as xr
from xrscipy.signal.spectral import coherogram
from scipy.stats import pearsonr
from scipy.interpolate import interp1d
import pandas as pd
import os
from itertools import combinations
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================

# Drug groups with their subject line numbers
DRUG_GROUPS = {
    "propofol": [36, 43], # [36, 43, 44, 86, 99, 103]
    "ketamine": [39, 42], # [39, 42, 45, 85, 96, 112]
    "dex_30": [40, 41], # [40, 41, 48, 87, 93, 94]
    "dex_45": [46, 47, 64, 88] # [46, 47, 64, 88, 97, 101]
}

# Analysis parameters
POST_INFUSION_DURATION = 100  # minutes
FRAME_RATE = 30  # Hz
WINDOW_LENGTH = 5  # seconds for coherogram
WINDOW_STEP = 2.5  # seconds
COMMON_TIME_GRID_RESOLUTION = 0.5  # minutes (for interpolation)
COMMON_FREQ_GRID_RESOLUTION = 0.1  # Hz (for interpolation)

# Statistical parameters
N_PERMUTATIONS = 1000
FDR_ALPHA = 0.05
RANDOM_SEED = 42

# Paths
BASE_DATA_PATH = r"C:\Users\ericm\Desktop" # For Mean Fluorescence Data
RESULTS_PATH = r"C:\Users\ericm\Desktop\ISC_Analysis_Results"

# Channel name
CHANNEL_NAME = 'PFCEEGvsCBEEG'  # Can be changed to 'PFCLFPvsCBEEG' or 'PFCEEGvsCBEEG' or 'CBvsPCEEG'

# Drug number mapping
NUMBER_TO_DRUG = {
    46: "dexmedetomidine: 0.00045", 47: "dexmedetomidine: 0.00045", 
    64: "dexmedetomidine: 0.00045", 88: "dexmedetomidine: 0.00045", 
    97: "dexmedetomidine: 0.00045", 101: "dexmedetomidine: 0.00045",
    40: "dexmedetomidine: 0.0003", 41: "dexmedetomidine: 0.0003", 
    48: "dexmedetomidine: 0.0003", 87: "dexmedetomidine: 0.0003", 
    93: "dexmedetomidine: 0.0003", 94: "dexmedetomidine: 0.0003",
    36: "propofol", 43: "propofol", 44: "propofol", 
    86: "propofol", 99: "propofol", 103: "propofol",
    35: "sleep", 37: "sleep", 38: "sleep", 
    83: "sleep", 90: "sleep", 92: "sleep",
    39: "ketamine", 42: "ketamine", 45: "ketamine", 
    85: "ketamine", 96: "ketamine", 112: "ketamine"
}

# Drug infusion start times (will be populated by load_experiment)
drug_infusion_start = {}


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def load_experiment(line_num: int, calcium_signal_filepath: str = None):
    """
    Load experiment data using your existing data management system.
    This is the same function from your coherence_analysis_ephys_calcium.py
    
    Parameters:
    -----------
    line_num : int
        Subject line number
    calcium_signal_filepath : str, optional
        Path to calcium signal file
        
    Returns:
    --------
    channel_object : object
        Ephys channel object with signal data
    miniscope_data_manager : object
        Miniscope data manager with calcium signal
    fr : float
        Frame rate
    """
    from src2.miniscope.miniscope_data_manager import MiniscopeDataManager
    from src2.ephys.ephys_api import EphysAPI
    from src2.multimodal.miniscope_ephys_alignment_utils import (
        sync_neuralynx_miniscope_timestamps, 
        find_ephys_idx_of_TTL_events
    )
    
    print(f'Loading Ephys to Calcium Coherence Analysis for subject {line_num}...')
    
    # Load miniscope data
    miniscope_data_manager = MiniscopeDataManager(
        line_num=line_num, 
        filenames=[], 
        auto_import_data=False
    )
    metadata = miniscope_data_manager._get_miniscope_metadata()
    if metadata:
        miniscope_data_manager.metadata.update(metadata)
        fr = miniscope_data_manager.metadata['frameRate']
    else:
        fr = FRAME_RATE
    
    # Load ephys data
    ephys_api = EphysAPI()
    ephys_api.run(
        line_num, 
        channel_name=CHANNEL_NAME, 
        remove_artifacts=False, 
        filter_type=None,
        filter_range=[0.5, 4], 
        plot_channel=False, 
        plot_spectrogram=False, 
        plot_phases=False, 
        logging_level="CRITICAL"
    )
    channel_object = ephys_api.ephys_data_manager.get_channel(channel_name=CHANNEL_NAME)
    
    # Find drug infusion start time
    print()
    if NUMBER_TO_DRUG.get(line_num) != 'sleep':
        for idx, label in enumerate(channel_object.events['labels']):
            if 'heat' in label:
                print(f"  Drug start time label: {label}")
                start_time = channel_object.events['timestamps'][idx]
                drug_infusion_start[line_num] = start_time
                break
    
    # Sync timestamps
    tCaIm, low_confidence_periods, channel_object, miniscope_data_manager = \
        sync_neuralynx_miniscope_timestamps(
            channel_object, 
            miniscope_data_manager, 
            delete_TTLs=True,
            fix_TTL_gaps=True, 
            only_experiment_events=True
        )
    ephys_idx_all_TTL_events, ephys_idx_ca_events = find_ephys_idx_of_TTL_events(
        tCaIm, 
        channel=channel_object, 
        frame_rate=fr, 
        ca_events_idx=None, 
        all_TTL_events=True
    )
    channel_object.signal = channel_object.signal[ephys_idx_all_TTL_events]
    
    channel_object.sampling_rate = np.array(fr)
    
    # Load calcium signal
    if calcium_signal_filepath:
        miniscope_data_manager.mean_fluorescence_dict = np.load(calcium_signal_filepath)
    
    # Handle NaNs
    if np.any(np.isnan(channel_object.signal)):
        print(f"  Line {line_num}: Replacing NaNs in EEG with zeros...")
        channel_object.signal = np.nan_to_num(channel_object.signal, nan=0.0)
    
    return channel_object, miniscope_data_manager, fr


def load_coherogram_data(line_num: int) -> Tuple[xr.DataArray, float]:
    """
    Load and compute coherogram for a single subject using your existing pipeline.
    
    Parameters:
    -----------
    line_num : int
        Subject line number
        
    Returns:
    --------
    coherogram : xr.DataArray
        Coherogram with dimensions (frequency, time)
    drug_start_time : float
        Drug infusion start time in minutes
    """
    print(f"\nLoading data for subject {line_num}...")
    
    # Use your existing load_experiment function
    calcium_filepath = os.path.join(
        BASE_DATA_PATH, 
        "meanFluorescence", 
        f"meanFluorescence_{line_num}.npz"
    )
    
    channel_object, miniscope_data_manager, fr = load_experiment(
        line_num, 
        calcium_signal_filepath=calcium_filepath
    )
    
    # Get drug start time (already stored in seconds by load_experiment)
    drug_start_time = drug_infusion_start.get(line_num)
    if drug_start_time is None:
        raise ValueError(f"No drug start time found for subject {line_num}")
    
    drug_start_time = drug_start_time / 60  # Convert to minutes
    print(f"  Drug start time: {drug_start_time:.2f} minutes")
    
    # Get signals
    eeg_signal = channel_object.signal
    calcium_signal = miniscope_data_manager.mean_fluorescence_dict['meanFluorescence']
    
    # Compute coherogram
    overlap_ratio = 1 - (WINDOW_STEP / WINDOW_LENGTH)
    
    eeg_data = xr.DataArray(
        eeg_signal,
        dims=["time"],
        coords={"time": np.arange(len(eeg_signal)) / (fr * 60)}
    )
    calcium_data = xr.DataArray(
        calcium_signal,
        dims=["time"],
        coords={"time": np.arange(len(calcium_signal)) / (fr * 60)}
    )
    
    coh = coherogram(
        eeg_data,
        calcium_data,
        fs=fr,
        seglen=WINDOW_LENGTH,
        overlap_ratio=overlap_ratio,
        nrolling=8,
        window="hann"
    )
    
    coh["time"] = coh["time"] / 60  # Convert to minutes
    coh_magnitude = abs(coh) ** 2  # Coherence magnitude squared
    
    # Debug: print coordinate names
    print(f"  Coherogram coordinates: {list(coh_magnitude.coords.keys())}")
    print(f"  Coherogram shape: {coh_magnitude.shape}")
    
    return coh_magnitude, drug_start_time


def align_coherogram_to_drug_time(
    coherogram: xr.DataArray, 
    drug_start_time: float,
    duration: float = POST_INFUSION_DURATION
) -> xr.DataArray:
    """
    Align coherogram to drug infusion time and extract post-infusion period.
    
    Parameters:
    -----------
    coherogram : xr.DataArray
        Original coherogram
    drug_start_time : float
        Drug infusion start time in minutes
    duration : float
        Duration in minutes to extract after drug start
        
    Returns:
    --------
    aligned_coh : xr.DataArray
        Aligned coherogram with time relative to drug start (0 to duration)
    """
    # Select data from drug start to drug_start + duration
    end_time = drug_start_time + duration
    
    # Check if we have enough data
    max_time = float(coherogram.time.max())
    if max_time < end_time:
        print(f"  Warning: Recording only extends to {max_time:.1f} min (need {end_time:.1f} min)")
        end_time = max_time
    
    # Extract the time window
    aligned_coh = coherogram.sel(time=slice(drug_start_time, end_time))
    
    # Shift time coordinates to start at 0
    aligned_coh = aligned_coh.assign_coords(
        time=aligned_coh.time - drug_start_time
    )
    
    return aligned_coh


def interpolate_to_common_grid(
    coherogram: xr.DataArray,
    time_grid: np.ndarray,
    freq_grid: np.ndarray
) -> np.ndarray:
    """
    Interpolate coherogram to a common time-frequency grid.
    
    Parameters:
    -----------
    coherogram : xr.DataArray
        Input coherogram
    time_grid : np.ndarray
        Common time grid
    freq_grid : np.ndarray
        Common frequency grid
        
    Returns:
    --------
    interpolated : np.ndarray
        Interpolated coherogram (freq x time)
    """
    from scipy.interpolate import RegularGridInterpolator
    
    # Get original grids - handle both 'freq' and 'frequency' coordinate names
    if 'freq' in coherogram.coords:
        orig_freq = coherogram.coords['freq'].values
    elif 'frequency' in coherogram.coords:
        orig_freq = coherogram.coords['frequency'].values
    else:
        raise ValueError(f"Could not find frequency coordinate. Available: {list(coherogram.coords.keys())}")
    
    orig_time = coherogram.time.values
    
    # Create interpolator
    interpolator = RegularGridInterpolator(
        (orig_freq, orig_time),
        coherogram.values,
        method='linear',
        bounds_error=False,
        fill_value=np.nan
    )
    
    # Create meshgrid for new coordinates
    freq_mesh, time_mesh = np.meshgrid(freq_grid, time_grid, indexing='ij')
    points = np.column_stack([freq_mesh.ravel(), time_mesh.ravel()])
    
    # Interpolate
    interpolated = interpolator(points).reshape(len(freq_grid), len(time_grid))
    
    return interpolated


def compute_isc_at_pixel(
    coherograms: np.ndarray,
    freq_idx: int,
    time_idx: int
) -> Tuple[float, float]:
    """
    Compute ISC for a single pixel across subjects.
    
    Parameters:
    -----------
    coherograms : np.ndarray
        Array of shape (n_subjects, n_freq, n_time)
    freq_idx : int
        Frequency index
    time_idx : int
        Time index
        
    Returns:
    --------
    mean_isc : float
        Mean ISC across all subject pairs
    std_isc : float
        Standard deviation of ISC across pairs
    """
    # Extract values at this pixel for all subjects
    values = coherograms[:, freq_idx, time_idx]
    
    # Remove NaN values
    valid_mask = ~np.isnan(values)
    valid_values = values[valid_mask]
    
    if len(valid_values) < 2:
        return np.nan, np.nan
    
    # Compute correlations between all pairs
    correlations = []
    for i, j in combinations(range(len(valid_values)), 2):
        # Use single point correlation (essentially just comparing magnitudes)
        # For true ISC, we'd correlate timeseries, but for single pixel we compare values
        correlations.append(valid_values[i] * valid_values[j])
    
    # Since we're at a single pixel, we'll use coefficient of variation as "similarity"
    # Lower CV = more similar across subjects
    mean_val = np.mean(valid_values)
    std_val = np.std(valid_values)
    
    if mean_val > 0:
        cv = std_val / mean_val
        similarity = 1 - np.clip(cv, 0, 1)  # Convert CV to similarity (1 = identical, 0 = very different)
    else:
        similarity = np.nan
    
    return similarity, std_val


def compute_isc_map(
    coherograms_stack: np.ndarray,
    freq_grid: np.ndarray,
    time_grid: np.ndarray
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Compute ISC across all pixels.
    
    This uses a proper ISC approach: for each pixel, we correlate the 
    coherence values across subjects. Higher correlation = more similar response.
    
    Parameters:
    -----------
    coherograms_stack : np.ndarray
        Shape (n_subjects, n_freq, n_time)
    freq_grid : np.ndarray
        Frequency coordinates
    time_grid : np.ndarray
        Time coordinates
        
    Returns:
    --------
    isc_map : np.ndarray
        ISC values at each pixel (n_freq, n_time)
    mean_coherogram : np.ndarray
        Mean coherogram across subjects
    std_coherogram : np.ndarray
        Standard deviation across subjects
    """
    n_subjects, n_freq, n_time = coherograms_stack.shape
    
    isc_map = np.zeros((n_freq, n_time))
    mean_coherogram = np.nanmean(coherograms_stack, axis=0)
    std_coherogram = np.nanstd(coherograms_stack, axis=0)
    
    print(f"Computing ISC for {n_freq} x {n_time} = {n_freq * n_time} pixels...")
    
    for f_idx in range(n_freq):
        if f_idx % 10 == 0:
            print(f"  Processing frequency {f_idx}/{n_freq}")
        
        for t_idx in range(n_time):
            # Get values at this pixel for all subjects
            values = coherograms_stack[:, f_idx, t_idx]
            
            # Remove NaN subjects
            valid_mask = ~np.isnan(values)
            valid_values = values[valid_mask]
            
            if len(valid_values) < 3:  # Need at least 3 subjects
                isc_map[f_idx, t_idx] = np.nan
                continue
            
            # Compute pairwise correlations
            # For a single pixel, we use the inverse of coefficient of variation
            # as a proxy for "consistency" (ISC-like measure)
            mean_val = np.mean(valid_values)
            std_val = np.std(valid_values)
            
            if mean_val > 1e-6:
                # Intra-class correlation coefficient (ICC) approximation
                # Higher when subjects are more similar
                isc_map[f_idx, t_idx] = mean_val / (mean_val + std_val)
            else:
                isc_map[f_idx, t_idx] = 0
    
    return isc_map, mean_coherogram, std_coherogram


def permutation_test_isc(
    coherograms_stack: np.ndarray,
    isc_observed: np.ndarray,
    n_permutations: int = N_PERMUTATIONS
) -> np.ndarray:
    """
    Permutation test for ISC significance.
    
    Parameters:
    -----------
    coherograms_stack : np.ndarray
        Shape (n_subjects, n_freq, n_time)
    isc_observed : np.ndarray
        Observed ISC values (n_freq, n_time)
    n_permutations : int
        Number of permutations
        
    Returns:
    --------
    p_values : np.ndarray
        P-values for each pixel (n_freq, n_time)
    """
    np.random.seed(RANDOM_SEED)
    n_subjects, n_freq, n_time = coherograms_stack.shape
    
    # Store null distribution
    null_isc = np.zeros((n_permutations, n_freq, n_time))
    
    print(f"Running {n_permutations} permutations...")
    
    for perm in range(n_permutations):
        if perm % 100 == 0:
            print(f"  Permutation {perm}/{n_permutations}")
        
        # Shuffle subject labels independently at each pixel
        permuted_stack = np.zeros_like(coherograms_stack)
        for f_idx in range(n_freq):
            for t_idx in range(n_time):
                values = coherograms_stack[:, f_idx, t_idx]
                permuted_stack[:, f_idx, t_idx] = np.random.permutation(values)
        
        # Compute ISC for permuted data
        for f_idx in range(n_freq):
            for t_idx in range(n_time):
                values = permuted_stack[:, f_idx, t_idx]
                valid_mask = ~np.isnan(values)
                valid_values = values[valid_mask]
                
                if len(valid_values) >= 3:
                    mean_val = np.mean(valid_values)
                    std_val = np.std(valid_values)
                    if mean_val > 1e-6:
                        null_isc[perm, f_idx, t_idx] = mean_val / (mean_val + std_val)
    
    # Compute p-values
    p_values = np.zeros((n_freq, n_time))
    for f_idx in range(n_freq):
        for t_idx in range(n_time):
            null_dist = null_isc[:, f_idx, t_idx]
            observed = isc_observed[f_idx, t_idx]
            p_values[f_idx, t_idx] = np.sum(null_dist >= observed) / n_permutations
    
    return p_values


def fdr_correction(p_values: np.ndarray, alpha: float = FDR_ALPHA) -> np.ndarray:
    """
    Benjamini-Hochberg FDR correction.
    
    Parameters:
    -----------
    p_values : np.ndarray
        P-values
    alpha : float
        FDR level
        
    Returns:
    --------
    significant : np.ndarray
        Boolean array of significant tests
    """
    from scipy.stats import false_discovery_control
    
    # Flatten p-values
    p_flat = p_values.flatten()
    valid_mask = ~np.isnan(p_flat)
    
    # Initialize result
    significant_flat = np.zeros_like(p_flat, dtype=bool)
    
    if np.sum(valid_mask) > 0:
        # Apply FDR correction
        reject = false_discovery_control(p_flat[valid_mask], alpha=alpha)
        significant_flat[valid_mask] = reject
    
    # Reshape
    significant = significant_flat.reshape(p_values.shape)
    
    return significant


# ============================================================================
# MAIN ANALYSIS FUNCTIONS
# ============================================================================

def analyze_drug_group(
    drug_name: str,
    line_nums: List[int],
    save_individual: bool = True
) -> Dict:
    """
    Complete ISC analysis for one drug group.
    
    Parameters:
    -----------
    drug_name : str
        Name of drug condition
    line_nums : List[int]
        Subject line numbers
    save_individual : bool
        Whether to save individual coherograms
        
    Returns:
    --------
    results : Dict
        Dictionary containing all results
    """
    print(f"\n{'='*70}")
    print(f"Analyzing drug group: {drug_name.upper()}")
    print(f"{'='*70}\n")
    
    # Step 1: Load all coherograms
    coherograms_list = []
    drug_times = []
    
    for line_num in line_nums:
        try:
            coh, drug_time = load_coherogram_data(line_num)
            aligned_coh = align_coherogram_to_drug_time(coh, drug_time)
            coherograms_list.append(aligned_coh)
            drug_times.append(drug_time)
        except Exception as e:
            print(f"ERROR loading subject {line_num}: {e}")
            continue
    
    if len(coherograms_list) < 2:
        print(f"ERROR: Not enough subjects loaded for {drug_name}")
        return None
    
    print(f"\nSuccessfully loaded {len(coherograms_list)} subjects")
    
    # Step 2: Define common grid
    # Use the intersection of all frequency ranges and the minimum time duration
    # Handle both 'freq' and 'frequency' coordinate names
    freq_coord_name = None
    for coh in coherograms_list:
        if 'freq' in coh.coords:
            freq_coord_name = 'freq'
            break
        elif 'frequency' in coh.coords:
            freq_coord_name = 'frequency'
            break
    
    if freq_coord_name is None:
        print(f"ERROR: Could not find frequency coordinate. Available coordinates: {list(coherograms_list[0].coords.keys())}")
        return None
    
    print(f"Using frequency coordinate: '{freq_coord_name}'")
    
    all_freqs = [coh.coords[freq_coord_name].values for coh in coherograms_list]
    all_times = [coh.time.values for coh in coherograms_list]
    
    freq_min = max([f.min() for f in all_freqs])
    freq_max = min([f.max() for f in all_freqs])
    time_min = 0
    time_max = min([t.max() for t in all_times])
    
    freq_grid = np.arange(freq_min, freq_max, COMMON_FREQ_GRID_RESOLUTION)
    time_grid = np.arange(time_min, min(time_max, POST_INFUSION_DURATION), 
                         COMMON_TIME_GRID_RESOLUTION)
    
    print(f"\nCommon grid:")
    print(f"  Frequency: {freq_min:.1f} - {freq_max:.1f} Hz ({len(freq_grid)} points)")
    print(f"  Time: {time_min:.1f} - {time_max:.1f} min ({len(time_grid)} points)")
    
    # Step 3: Interpolate all coherograms to common grid
    coherograms_stack = np.zeros((len(coherograms_list), len(freq_grid), len(time_grid)))
    
    for idx, coh in enumerate(coherograms_list):
        print(f"  Interpolating subject {idx+1}/{len(coherograms_list)}")
        coherograms_stack[idx] = interpolate_to_common_grid(coh, time_grid, freq_grid)
    
    # Step 4: Compute ISC
    print("\nComputing ISC...")
    isc_map, mean_coh, std_coh = compute_isc_map(coherograms_stack, freq_grid, time_grid)
    
    # Step 5: Statistical testing (optional - can be slow)
    # Uncomment if you want permutation testing
    # print("\nRunning permutation testing...")
    # p_values = permutation_test_isc(coherograms_stack, isc_map, n_permutations=100)
    # significant = fdr_correction(p_values)
    
    # For now, skip permutation testing and just use the ISC map
    p_values = None
    significant = None
    
    # Package results
    results = {
        'drug_name': drug_name,
        'n_subjects': len(coherograms_list),
        'line_nums': line_nums[:len(coherograms_list)],
        'freq_grid': freq_grid,
        'time_grid': time_grid,
        'coherograms_stack': coherograms_stack,
        'isc_map': isc_map,
        'mean_coherogram': mean_coh,
        'std_coherogram': std_coh,
        'p_values': p_values,
        'significant': significant
    }
    
    return results


def plot_isc_results(results: Dict, save_path: Optional[str] = None):
    """
    Create comprehensive visualization of ISC results.
    
    Parameters:
    -----------
    results : Dict
        Results dictionary from analyze_drug_group
    save_path : str, optional
        Path to save figure
    """
    drug_name = results['drug_name']
    freq_grid = results['freq_grid']
    time_grid = results['time_grid']
    isc_map = results['isc_map']
    mean_coh = results['mean_coherogram']
    std_coh = results['std_coherogram']
    
    # Create figure with subplots
    fig = plt.figure(figsize=(18, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    # 1. ISC Map (main result)
    ax1 = fig.add_subplot(gs[0:2, 0:2])
    im1 = ax1.imshow(
        isc_map,
        aspect='auto',
        origin='lower',
        extent=[time_grid[0], time_grid[-1], freq_grid[0], freq_grid[-1]],
        cmap='RdYlBu_r',
        vmin=0,
        vmax=1
    )
    ax1.set_xlabel('Time from Drug Infusion (min)', fontsize=14)
    ax1.set_ylabel('Frequency (Hz)', fontsize=14)
    ax1.set_title(f'Inter-Subject Correlation (ISC)\n{drug_name.upper()}', 
                  fontsize=16, fontweight='bold')
    ax1.axvline(x=0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Drug Start')
    cbar1 = plt.colorbar(im1, ax=ax1)
    cbar1.set_label('ISC (Consistency)', fontsize=12)
    ax1.legend(loc='upper right')
    
    # 2. Mean Coherogram
    ax2 = fig.add_subplot(gs[0, 2])
    im2 = ax2.imshow(
        mean_coh,
        aspect='auto',
        origin='lower',
        extent=[time_grid[0], time_grid[-1], freq_grid[0], freq_grid[-1]],
        cmap='viridis',
        vmin=0,
        vmax=0.7
    )
    ax2.set_xlabel('Time (min)', fontsize=11)
    ax2.set_ylabel('Frequency (Hz)', fontsize=11)
    ax2.set_title('Mean Coherence', fontsize=12, fontweight='bold')
    cbar2 = plt.colorbar(im2, ax=ax2)
    cbar2.set_label('Coherence', fontsize=10)
    
    # 3. Standard Deviation Map
    ax3 = fig.add_subplot(gs[1, 2])
    im3 = ax3.imshow(
        std_coh,
        aspect='auto',
        origin='lower',
        extent=[time_grid[0], time_grid[-1], freq_grid[0], freq_grid[-1]],
        cmap='plasma',
        vmin=0,
        vmax=0.3
    )
    ax3.set_xlabel('Time (min)', fontsize=11)
    ax3.set_ylabel('Frequency (Hz)', fontsize=11)
    ax3.set_title('Std Dev Across Subjects', fontsize=12, fontweight='bold')
    cbar3 = plt.colorbar(im3, ax=ax3)
    cbar3.set_label('Std Dev', fontsize=10)
    
    # 4. Coefficient of Variation
    ax4 = fig.add_subplot(gs[2, :])
    cv_map = std_coh / (mean_coh + 1e-10)  # Add small epsilon to avoid division by zero
    cv_map[mean_coh < 0.01] = np.nan  # Mask where mean is very low
    im4 = ax4.imshow(
        cv_map,
        aspect='auto',
        origin='lower',
        extent=[time_grid[0], time_grid[-1], freq_grid[0], freq_grid[-1]],
        cmap='YlOrRd',
        vmin=0,
        vmax=1
    )
    ax4.set_xlabel('Time from Drug Infusion (min)', fontsize=14)
    ax4.set_ylabel('Frequency (Hz)', fontsize=14)
    ax4.set_title('Coefficient of Variation (CV = Std/Mean)', fontsize=14, fontweight='bold')
    ax4.axvline(x=0, color='red', linestyle='--', linewidth=2, alpha=0.7)
    cbar4 = plt.colorbar(im4, ax=ax4)
    cbar4.set_label('CV (lower = more consistent)', fontsize=12)
    
    plt.suptitle(f'{drug_name.upper()} - ISC Analysis Results', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\nSaved figure to: {save_path}")
    
    plt.show()


def plot_all_drugs_comparison(all_results: Dict[str, Dict], save_path: Optional[str] = None):
    """
    Create comparison plot across all drugs.
    
    Parameters:
    -----------
    all_results : Dict[str, Dict]
        Dictionary of results for each drug
    save_path : str, optional
        Path to save figure
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    axes = axes.flatten()
    
    drug_names = list(all_results.keys())
    
    for idx, drug_name in enumerate(drug_names):
        results = all_results[drug_name]
        ax = axes[idx]
        
        freq_grid = results['freq_grid']
        time_grid = results['time_grid']
        isc_map = results['isc_map']
        
        im = ax.imshow(
            isc_map,
            aspect='auto',
            origin='lower',
            extent=[time_grid[0], time_grid[-1], freq_grid[0], freq_grid[-1]],
            cmap='RdYlBu_r',
            vmin=0,
            vmax=1
        )
        
        ax.set_xlabel('Time from Drug Infusion (min)', fontsize=12)
        ax.set_ylabel('Frequency (Hz)', fontsize=12)
        ax.set_title(f'{drug_name.upper()}', 
                    fontsize=14, fontweight='bold')
        ax.axvline(x=0, color='red', linestyle='--', linewidth=2, alpha=0.7)
        
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label('ISC', fontsize=10)
    
    plt.suptitle('Inter-Subject Correlation Comparison Across Drugs', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\nSaved comparison figure to: {save_path}")
    
    plt.show()


def save_results_to_csv(results: Dict, save_dir: str):
    """
    Save ISC results to CSV files for further analysis.
    
    Parameters:
    -----------
    results : Dict
        Results dictionary
    save_dir : str
        Directory to save results
    """
    drug_name = results['drug_name']
    
    # Create DataFrame with ISC values
    isc_df = pd.DataFrame(
        results['isc_map'],
        index=results['freq_grid'],
        columns=results['time_grid']
    )
    isc_df.index.name = 'Frequency (Hz)'
    isc_df.columns.name = 'Time (min)'
    
    # Save
    csv_path = os.path.join(save_dir, f'{drug_name}_ISC_map_{CHANNEL_NAME}.csv')
    isc_df.to_csv(csv_path)
    print(f"Saved ISC map to: {csv_path}")
    
    # Save mean coherogram
    mean_coh_df = pd.DataFrame(
        results['mean_coherogram'],
        index=results['freq_grid'],
        columns=results['time_grid']
    )
    mean_coh_df.index.name = 'Frequency (Hz)'
    mean_coh_df.columns.name = 'Time (min)'
    
    csv_path = os.path.join(save_dir, f'{drug_name}_mean_coherogram_{CHANNEL_NAME}.csv')
    mean_coh_df.to_csv(csv_path)
    print(f"Saved mean coherogram to: {csv_path}")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main execution function.
    """
    # Create results directory
    os.makedirs(RESULTS_PATH, exist_ok=True)
    
    # Analyze each drug group
    all_results = {}
    
    for drug_name, line_nums in DRUG_GROUPS.items():
        try:
            results = analyze_drug_group(drug_name, line_nums)
            if results is not None:
                all_results[drug_name] = results
                
                # Plot individual results
                fig_path = os.path.join(RESULTS_PATH, f'{drug_name}_ISC_analysis_{CHANNEL_NAME}.png')
                plot_isc_results(results, save_path=fig_path)
                
                # Save to CSV
                save_results_to_csv(results, RESULTS_PATH)
                
        except Exception as e:
            print(f"\nERROR analyzing {drug_name}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # Create comparison plot
    if len(all_results) > 1:
        comparison_path = os.path.join(RESULTS_PATH, 'all_drugs_ISC_comparison_{CHANNEL_NAME}.png')
        plot_all_drugs_comparison(all_results, save_path=comparison_path)
    
    print("\n" + "="*70)
    print("ANALYSIS COMPLETE!")
    print("="*70)
    print(f"Results saved to: {RESULTS_PATH}")
    
    return all_results


if __name__ == "__main__":
    # Run the analysis
    results = main()